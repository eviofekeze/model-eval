{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de785ea-2c08-4201-97a4-eb1a9db17150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataIO_funcs\n",
    "# from datetime import datetime\n",
    "import datetime\n",
    "import numpy as np\n",
    "import dateutil.parser\n",
    "import os\n",
    "import subprocess\n",
    "from snowexsql.db import get_db\n",
    "from snowexsql.data import LayerData,PointData# Import the function to get connect to the db\n",
    "from snowexsql.conversions import query_to_geopandas # Import a useful function to format that data into a dataframe \n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, LineString, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "caa93aff-1710-47ba-8aeb-68679734b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify paths\n",
    "bucket_name = 'eis-dh-hydro/SNOWEX-HACKWEEK'\n",
    "LIS_path = f's3://{bucket_name}/2022/ZARR/SURFACEMODEL/LIS_HIST_default_chunks.d01.zarr/'\n",
    "# LIS_path = f's3://{bucket_name}/2022/ZARR/SURFACEMODEL/LIS_HIST_rechunkedV4.d01.zarr'\n",
    "SWESARR_url = 'https://glihtdata.gsfc.nasa.gov/files/radar/SWESARR/prerelease/'\n",
    "\n",
    "# SWESARR data website\n",
    "source_repo = 'https://glihtdata.gsfc.nasa.gov/files/radar/SWESARR/prerelease/'\n",
    "\n",
    "# specify filters\n",
    "time_sel='2020-02-08'\n",
    "lat_range = [38.8, 38.9]\n",
    "lon_range = [-108.5, -107.5]\n",
    "model_variable = ['SM_SWE_inst','SM_SnowDepth_inst']\n",
    "dx = 0.0011\n",
    "dy = 0.0009\n",
    "time_buffer_dy = 2\n",
    "\n",
    "db_name = 'snow:hackweek@db.snowexdata.org/snowex' # This is what you will use for all of hackweek to access the db\n",
    "type_name = 'point'\n",
    "var_name = 'swe'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9aca6d-595a-4a3c-b70d-1758d36a086d",
   "metadata": {},
   "source": [
    "# FOR PULLING SWESARR\n",
    "#### TAKES A LOOK AT ALL OF THE DATA AVAILABLE, THEN ATTAEMPTS TO PULL THE DATA THAT IS 'TIME_BUFFER_DY' FROM THE SPECIFIED DAY 'TIME_SEL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f3ce8e9-b319-4b04-b242-b6a4efd27073",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'dataIO_funcs' has no attribute 'access_SWESAR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# pull the dates that SWESARR occurred\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdataIO_funcs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccess_SWESAR\u001b[49m\n\u001b[1;32m      3\u001b[0m SWESARR_names,SWESARR_dates \u001b[38;5;241m=\u001b[39m dataIO_funcs\u001b[38;5;241m.\u001b[39maccess_SWESARR\u001b[38;5;241m.\u001b[39mget_url_paths(SWESARR_url)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(SWESARR_names)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'dataIO_funcs' has no attribute 'access_SWESAR'"
     ]
    }
   ],
   "source": [
    "# pull the dates that SWESARR occurred\n",
    "dataIO_funcs.access_SWESAR\n",
    "SWESARR_names,SWESARR_dates = dataIO_funcs.access_SWESARR.get_url_paths(SWESARR_url)\n",
    "print(SWESARR_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2ae8fb2-6bf7-4df1-b992-42dea7c25497",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://glihtdata.gsfc.nasa.gov/files/radar/SWESARR/prerelease//GRMCT2_13802_20006_012_200210_225_XX_01/\n",
      "https://glihtdata.gsfc.nasa.gov/files/radar/SWESARR/prerelease//GRMCT2_31601_20006_011_200210_225_XX_01/\n",
      "https://glihtdata.gsfc.nasa.gov/files/radar/SWESARR/prerelease//GRMNT1_09302_20006_009_200210_225_XX_01/\n",
      "https://glihtdata.gsfc.nasa.gov/files/radar/SWESARR/prerelease//GRMNT1_09401_20006_005_200210_225_XX_01/\n",
      "https://glihtdata.gsfc.nasa.gov/files/radar/SWESARR/prerelease//GRMST1_27302_20006_007_200210_225_XX_01/\n",
      "https://glihtdata.gsfc.nasa.gov/files/radar/SWESARR/prerelease//GRMST1_27501_20006_003_200210_225_XX_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wget: missing URL\n",
      "Usage: wget [OPTION]... [URL]...\n",
      "\n",
      "Try `wget --help' for more options.\n",
      "wget: missing URL\n",
      "Usage: wget [OPTION]... [URL]...\n",
      "\n",
      "Try `wget --help' for more options.\n",
      "wget: missing URL\n",
      "Usage: wget [OPTION]... [URL]...\n",
      "\n",
      "Try `wget --help' for more options.\n",
      "wget: missing URL\n",
      "Usage: wget [OPTION]... [URL]...\n",
      "\n",
      "Try `wget --help' for more options.\n",
      "wget: missing URL\n",
      "Usage: wget [OPTION]... [URL]...\n",
      "\n",
      "Try `wget --help' for more options.\n",
      "wget: missing URL\n",
      "Usage: wget [OPTION]... [URL]...\n",
      "\n",
      "Try `wget --help' for more options.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jovyan/model-eval/contributors/jupflug/GRMST1_27501_20006_003_200210_225_XX_01/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# ! wget -r -np -nH --reject \"indexd.html*\" -e robots=off -r --no-parent -A \"*tif\" source_repo + flight_line\u001b[39;00m\n\u001b[1;32m     15\u001b[0m data_files \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 16\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mflight_line\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     18\u001b[0m     data_files\u001b[38;5;241m.\u001b[39mappend(file)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jovyan/model-eval/contributors/jupflug/GRMST1_27501_20006_003_200210_225_XX_01/'"
     ]
    }
   ],
   "source": [
    "def date_between_prime(start_date, end_date, folder_date,folder_names):\n",
    "    result = [folder_names[i] for i in range(len(folder_date)) if (folder_date[i] >= start_date and folder_date[i] <= end_date)]\n",
    "    return result\n",
    "time_sel_newForm = dateutil.parser.parse(time_sel)\n",
    "start_date = time_sel_newForm-datetime.timedelta(days=time_buffer_dy)\n",
    "end_date = time_sel_newForm+datetime.timedelta(days=time_buffer_dy)\n",
    "\n",
    "final_files = date_between_prime(start_date, end_date, SWESARR_dates, SWESARR_names)\n",
    "for flight_line in final_files:\n",
    "    print(source_repo + flight_line)\n",
    "    # command = wget -r -np -nH --reject \"indexd.html*\" -e robots=off -r --no-parent -A \"*tif\" source_repo + flight_line\n",
    "    subprocess.Popen(['wget -r -np -nH --reject indexd.html* -e robots=off -r --no-parent -A *tif',source_repo+flight_line], shell=True)\n",
    "    # ! wget -r -np -nH --reject \"indexd.html*\" -e robots=off -r --no-parent -A \"*tif\" source_repo + flight_line\n",
    "    \n",
    "data_files = []\n",
    "os.chdir(os.getcwd() + flight_line)\n",
    "for file in glob.glob(\"*.tif\"):\n",
    "    data_files.append(file)\n",
    "    \n",
    "data_files = [data for data in data_files if data[-8:] != '_dem.tif']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a12307f-b92c-4c5a-b7cd-29c1873d3276",
   "metadata": {},
   "source": [
    "# LIS MODEL READ-IN\n",
    "#### READS IN THE DATA BASED ON THE LAT/LON/DATE CONSTRAINTS, PROVIDED THE MODEL VARIABLES OF FOCUS\n",
    "#### WE ALSO GIVE IT THE APPROXIMATE MODEL DX AND DY WE WANT TO MOVE TO WHEN CONVERTING TO A RECTANGULAR GRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "285ec4b2-3f8f-4019-a91c-0c2ed96da827",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_LIS = dataIO_funcs.access_LIS(lon_range,lat_range,time_sel,\n",
    "                             model_variable,LIS_path,dx,dy,'bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0da2a4e-5a32-4746-8c99-7aaf6001d582",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds_LIS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mds_LIS\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds_LIS' is not defined"
     ]
    }
   ],
   "source": [
    "ds_LIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3658ce6-2cbb-4932-87b9-e263420d4dd4",
   "metadata": {},
   "source": [
    "# POINT AND LAYER DATA READ-IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89f8e505-8168-414c-bd7b-7d0960d997a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.date(2020, 2, 8),)\n",
      "(datetime.date(2020, 2, 9),)\n",
      "(datetime.date(2020, 2, 6),)\n",
      "(datetime.date(2020, 2, 10),)\n",
      "(datetime.date(2020, 2, 7),)\n",
      "[[-107.7, 38.8], [-107.5, 38.8], [-107.5, 38.9], [-107.7, 38.9]]\n"
     ]
    }
   ],
   "source": [
    "df = dataIO_funcs.access_snowEx.access_pointData(db_name,time_sel,time_buffer_dy,var_name,lat_range,lon_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a035ff-6395-41e5-a084-17553b2a9658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
